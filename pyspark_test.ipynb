{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyspark\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.sql import SQLContext,Row\n",
    "from pyspark.mllib.classification import NaiveBayes\n",
    "from pyspark.mllib.tree import DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawdata=[\n",
    "['sunny',85,85,'FALSE',0, 1],\n",
    "['sunny',80,90,'TRUE',0, 1],\n",
    "['overcast',83,86,'FALSE',1, 1],\n",
    "['rainy',70,96,'FALSE',1, 1],\n",
    "['rainy',68,80,'FALSE',1, 1],\n",
    "['rainy',65,70,'TRUE',0, 1],\n",
    "['overcast',64,65,'TRUE',1, 1],\n",
    "['sunny',72,95,'FALSE',0, 1],\n",
    "['sunny',69,70,'FALSE',1, 1],\n",
    "['rainy',75,80,'FALSE',1, 1],\n",
    "['sunny',75,70,'TRUE',1, 1],\n",
    "['overcast',72,90,'TRUE',1, 1],\n",
    "['overcast',81,75,'FALSE',1, 1],\n",
    "['rainy',71,91,'TRUE',0, 1]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "data_df=sqlContext.createDataFrame(rawdata,\n",
    "   ['outlook','temp','humid','windy','play','mydummy'])\n",
    "\n",
    "#transform categoricals into indicator variables\n",
    "out2index={'sunny':[1,0,0],'overcast':[0,1,0],'rainy':[0,0,1]}\n",
    "\n",
    "#make RDD of labeled vectors\n",
    "def newrow(dfrow):\n",
    "    outrow = list(out2index.get((dfrow[0])))  #get dictionary entry for outlook\n",
    "    outrow.append(dfrow[1])   #temp\n",
    "    outrow.append(dfrow[2])   #humidity\n",
    "    if dfrow[3]=='TRUE':      #windy\n",
    "        outrow.append(1)\n",
    "    else:\n",
    "        outrow.append(0)\n",
    "    outrow.append(dfrow[5])\n",
    "    return (LabeledPoint(dfrow[4],outrow))\n",
    "\n",
    "datax_rdd=data_df.map(newrow)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.mllib.classification.NaiveBayesModel object at 0x7f3c81a75a90>\n",
      "[1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]\n",
      "Naive Bayes: Conf.Mat. and Per Corr\n",
      "[[ 3.  2.]\n",
      " [ 0.  9.]]\n",
      "0.857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/ipykernel/__main__.py:28: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "#execute model, it can go in a single pass\n",
    "nb_model = NaiveBayes.train(datax_rdd)\n",
    "\n",
    "#Some info on model \n",
    "print(nb_model)\n",
    "#some checks,get some of training data and test it:\n",
    "datax_col=datax_rdd.collect()   #if datax_rdd was big, use sample or take\n",
    "\n",
    "trainset_pred =[]\n",
    "for x in datax_col:\n",
    "    trainset_pred.append(nb_model.predict(x.features))\n",
    "\n",
    "print(trainset_pred)\n",
    "\n",
    "#to see class conditionals\n",
    "#you might have to install scipy\n",
    "#import scipy\n",
    "#print 'Class Cond Probabilities, ie p(attr|class= 0 or 1) '\n",
    "#print scipy.exp(my_nbmodel.theta)\n",
    "#print scipy.exp(my_nbmodel.pi)\n",
    "\n",
    "#get a confusion matrix\n",
    "#the row is the true class label 0 or 1, columns are predicted label\n",
    "#\n",
    "nb_cf_mat=np.zeros([2,2])  #num of classes\n",
    "for pnt in datax_col:\n",
    "    predctn = nb_model.predict(np.array(pnt.features))\n",
    "    nb_cf_mat[pnt.label][predctn]+=1\n",
    "\n",
    "corrcnt=0\n",
    "for i in range(2):\n",
    "    corrcnt+=nb_cf_mat[i][i]\n",
    "nb_per_corr=corrcnt/nb_cf_mat.sum()\n",
    "print('Naive Bayes: Conf.Mat. and Per Corr')\n",
    "print(nb_cf_mat)\n",
    "print(nb_per_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeModel classifier of depth 3 with 9 nodes\n",
      "  If (feature 1 <= 0.0)\n",
      "   If (feature 4 <= 80.0)\n",
      "    If (feature 3 <= 68.0)\n",
      "     Predict: 0.0\n",
      "    Else (feature 3 > 68.0)\n",
      "     Predict: 1.0\n",
      "   Else (feature 4 > 80.0)\n",
      "    If (feature 0 <= 0.0)\n",
      "     Predict: 0.0\n",
      "    Else (feature 0 > 0.0)\n",
      "     Predict: 0.0\n",
      "  Else (feature 1 > 0.0)\n",
      "   Predict: 1.0\n",
      "\n",
      "Decision Tree: Conf.Mat. and Per Corr\n",
      "[[ 5.  0.]\n",
      " [ 2.  7.]]\n",
      "0.857142857143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/ipykernel/__main__.py:35: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "# Decision tree model\n",
    "dt_model = DecisionTree.trainClassifier(datax_rdd,2,{},impurity='entropy',\n",
    "          maxDepth=5,maxBins=32, minInstancesPerNode=2)  \n",
    "\n",
    "#maxDepth and maxBins\n",
    "#{} could be categorical feature list,\n",
    "# To do regression, have no numclasses,and use trainRegression function\n",
    "print(dt_model.toDebugString())\n",
    "\n",
    "#results in this:\n",
    "#DecisionTreeModel classifier of depth 3 with 9 nodes\n",
    "#  If (feature 1 <= 0.0)\n",
    "#   If (feature 4 <= 80.0)\n",
    "#    If (feature 3 <= 68.0)\n",
    "#     Predict: 0.0\n",
    "#    Else (feature 3 > 68.0)\n",
    "#     Predict: 1.0\n",
    "#   Else (feature 4 > 80.0)\n",
    "#    If (feature 0 <= 0.0)\n",
    "#     Predict: 0.0\n",
    "#    Else (feature 0 > 0.0)\n",
    "#     Predict: 0.0\n",
    "#  Else (feature 1 > 0.0)\n",
    "#   Predict: 1.0\n",
    "\n",
    "#notice number of nodes are the predict (leaf nodes) and the ifs\n",
    "           \n",
    "#some checks,get some of training data and test it:\n",
    "datax_col=datax_rdd.collect()   #if datax_rdd was big, use sample or take\n",
    "\n",
    "#redo the conf. matrix code (it would be more efficient to pass a model)\n",
    "dt_cf_mat=np.zeros([2,2])  #num of classes\n",
    "for pnt in datax_col:\n",
    "    predctn = dt_model.predict(np.array(pnt.features))\n",
    "    dt_cf_mat[pnt.label][predctn]+=1\n",
    "corrcnt=0\n",
    "for i in range(2): \n",
    "    corrcnt+=dt_cf_mat[i][i]\n",
    "dt_per_corr=corrcnt/dt_cf_mat.sum()\n",
    "print('Decision Tree: Conf.Mat. and Per Corr')\n",
    "print(dt_cf_mat)\n",
    "print(dt_per_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "newpoint = np.array([1,0,0,68,79,0,1])\n",
    "print(nb_model.predict(newpoint))\n",
    "print(dt_model.predict(newpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
